# ğŸš€ Agent LLM Deployment System - Autonomous AI Web Developer

A **Brahmacode-inspired** autonomous AI agent designed to build, deploy, and update complete web applications from natural language project briefs. Built with **FastAPI**, **SQLAlchemy 2.0**, and modern async patterns.

## âœ¨ Key Features

- **ğŸ”„ Autonomous End-to-End Development**: Receives project briefs and handles entire development lifecycle
- **ğŸ¯ Multi-Round Capability**: Round 1 (new projects) and Round 2+ (updates) with RAG-powered context
- **ğŸ¤– Think-Plan-Act-Review Methodology**: Structured AI agent behavior for high-quality results
- **ğŸš€ Automated Deployment**: Creates GitHub repos and deploys to GitHub Pages automatically
- **ğŸ”§ Multi-LLM Provider Support**: OpenAI, Anthropic, Gemini, Copilot with automatic failover
- **ğŸ“š Interactive API Documentation**: Beautiful Swagger UI at `/docs`
- **ğŸ³ Production Ready**: Docker containerization with health checks
- **ğŸ“Š Comprehensive Monitoring**: Structured logging and observability

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ main.py              # FastAPI application entry point
â”œâ”€â”€ api/
â”‚   â””â”€â”€ routes.py        # API endpoints and request handling
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ orchestrator.py  # Core AI agent with Think-Plan-Act-Review
â”‚   â””â”€â”€ tools.py         # Agent tools for file system, Git, validation
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ database.py      # Async SQLAlchemy operations
â”‚   â”œâ”€â”€ github.py        # GitHub integration and deployment
â”‚   â””â”€â”€ llm.py           # Multi-provider LLM management
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ database.py      # SQLAlchemy models
â”‚   â””â”€â”€ schemas.py       # Pydantic API schemas
â””â”€â”€ core/
    â”œâ”€â”€ config.py        # Pydantic settings management
    â””â”€â”€ logging.py       # Structured logging configuration
```

## ğŸš€ Quick Start

### 1. Prerequisites

```bash
# Python 3.11+
# Git
# Node.js and npm (for ESLint)
# Google Chrome/Chromium (for Playwright)
```

### 2. Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd agent-llm-deployment

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
python -m playwright install chromium --with-deps
```

### 3. Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your API keys
# Required:
# - GITHUB_TOKEN (with repo permissions)
# - OPENAI_API_KEY or other LLM provider keys
# - HF_TOKEN (Hugging Face for database sync)
```

### 4. Run the Application

```bash
# Start the FastAPI server
python -m uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload

# Or use the run script
python run.py
```

The API will be available at `http://localhost:8000`

## ğŸ“– API Usage

### Interactive Documentation

Visit `http://localhost:8000/docs` for complete API documentation with:
- âœ… **Try it out** buttons for each endpoint
- âœ… **Request/response examples**
- âœ… **Model validation schemas**
- âœ… **Authentication requirements**

### Core Endpoints

#### Request Autonomous Development
```http
POST /api/request
Content-Type: application/json

{
  "email": "student@example.com",
  "secret": "your-secret-key",
  "nonce": "unique-request-id",
  "task": "markdown-converter-abc123",
  "round": 1,
  "brief": "Create a web app that converts Markdown to HTML in real-time",
  "checks": [
    "Must use a CDN Markdown parser",
    "Must have live preview",
    "Must be responsive"
  ],
  "evaluation_url": "https://your-callback-url.com"
}
```

**Response:**
```json
{
  "task": "markdown-converter-abc123",
  "status": "accepted",
  "message": "Task accepted and queued for autonomous processing",
  "nonce": "unique-request-id",
  "estimated_completion_time_minutes": 5
}
```

#### Check Task Status
```http
GET /api/status/{task_id}
```

#### Health Check
```http
GET /health
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `GITHUB_TOKEN` | GitHub Personal Access Token | âœ… |
| `OPENAI_API_KEY` | OpenAI API Key | âš ï¸* |
| `ANTHROPIC_API_KEY` | Anthropic Claude API Key | âš ï¸* |
| `GEMINI_API_KEYS` | Google Gemini API Keys (comma-separated) | âš ï¸* |
| `HF_TOKEN` | Hugging Face Token | âœ… |
| `DATABASE_ID` | Hugging Face Dataset ID | âœ… |

*At least one LLM provider required

### Advanced Configuration

```bash
# Multi-provider LLM setup
GEMINI_API_KEYS=key1,key2,key3
COPILOT_GITHUB_TOKEN=your-copilot-token

# Production settings
DEPLOYMENT_ENV=production
LOG_LEVEL=WARNING
MAX_CONCURRENT_TASKS=5
```

## ğŸ¤– Autonomous AI Agent

The system uses a sophisticated AI agent that follows the **Think-Plan-Act-Review** methodology:

1. **Think**: Analyze requirements and understand the task
2. **Plan**: Create detailed development plan with steps
3. **Act**: Execute development with code generation and validation
4. **Review**: Quality assurance and final validation

### Agent Capabilities

- **Code Generation**: HTML, CSS, JavaScript generation
- **File Management**: Workspace creation and file operations
- **Git Integration**: Repository creation and deployment
- **Quality Assurance**: Linting, validation, and testing
- **Multi-round Updates**: Context-aware modifications

## ğŸ³ Docker Deployment

### Development
```bash
# Build image
docker build -t agent-llm-deployment .

# Run container
docker run -p 8000:8000 \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/logs:/app/logs \
  agent-llm-deployment
```

### Production Deployment

**Render** (Recommended):
1. Connect your GitHub repository
2. Select Docker as runtime
3. Add environment variables
4. Deploy!

**Hugging Face Spaces**:
1. Create new Space with Docker
2. Upload `Dockerfile` and `src/`
3. Add environment variables
4. Deploy automatically

## ğŸ”’ Security Features

- **API Key Authentication**: Multiple LLM provider support
- **Rate Limiting**: Configurable request throttling
- **Input Validation**: Pydantic model validation
- **CORS Protection**: Configurable cross-origin policies
- **Secret Management**: Secure credential handling

## ğŸ“Š Monitoring & Observability

- **Structured Logging**: JSON-formatted logs with structlog
- **Health Checks**: Comprehensive system health monitoring
- **Error Tracking**: Ready for Sentry integration
- **Performance Metrics**: Prepared for Prometheus/Grafana

## ğŸ§ª Development

### Testing
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src

# Test specific module
pytest tests/test_api.py -v
```

### Code Quality
```bash
# Format code
black src/

# Sort imports
isort src/

# Lint code
flake8 src/

# Type check
mypy src/
```

## ğŸš§ Roadmap

- [ ] **Advanced RAG**: Vector-based code understanding for updates
- [ ] **WebSocket Support**: Real-time progress updates
- [ ] **Advanced Testing**: Browser automation and end-to-end tests
- [ ] **Plugin System**: Extensible tool architecture
- [ ] **Multi-tenancy**: Support for multiple organizations
- [ ] **Web UI**: React dashboard for task management

## ğŸ“ License

MIT License - see LICENSE file for details.

---

**Built with â¤ï¸ using FastAPI, SQLAlchemy 2.0, and the Think-Plan-Act-Review methodology**

*Inspired by Brahmacode - Autonomous AI Web Developer*
